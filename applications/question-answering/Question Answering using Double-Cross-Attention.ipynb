{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering using Double Cross Attention.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UU5tLStXHhMb",
        "VzjrrJkuHn8M",
        "o69fLv8lHxhh",
        "umR4XfZUH2Ob",
        "HGod6STqH52e",
        "aHrLacKrH-K-",
        "FucvadDuH_hj",
        "HmmGQepqIB_R",
        "gnLaYxvwIEoA",
        "abfffzq5IGv8"
      ],
      "authorship_tag": "ABX9TyPo31AG6jxK+YIQ0osKjSOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fquestion-answering/applications/question-answering/Question%20Answering%20using%20Double-Cross-Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuelqviTIQNG",
        "colab_type": "text"
      },
      "source": [
        "### Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x65t9U9SIPq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "31beb46d-263f-476e-88c7-aed08300d2e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jgp8A0HPjIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = \"/content/drive/My Drive/train-v1.1.json\"\n",
        "dev_file = \"/content/drive/My Drive/dev-v1.1.json\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVYZp0KrINz_",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhX4t24RgFFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import json\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHXqbdx5lPY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "422bd71b-9163-4de4-f71d-3f92a5e7f906"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR4_NM2Dxker",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f1bc9bd-608a-44b8-f118-63fe0cee5934"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7Q7ZX2-HanK",
        "colab_type": "text"
      },
      "source": [
        "### Parsing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2dcVEVnUa3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sequence):\n",
        "    tokens = [token.replace(\"``\", '\"').replace(\"''\", '\"').lower() for token in nltk.word_tokenize(sequence)]\n",
        "    return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmkUQv9OufoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_char_word_loc_mapping(context, context_tokens):\n",
        "    acc = \"\"\n",
        "    current_token_idx = 0\n",
        "    mapping = dict()\n",
        "    \n",
        "    for char_idx, char in enumerate(context):\n",
        "        if char != \" \" and char != '\\n':\n",
        "            acc += char\n",
        "            context_token = context_tokens[current_token_idx]\n",
        "            if acc == context_token:\n",
        "                syn_start = char_idx - len(acc) + 1\n",
        "                for char_loc in range(syn_start, char_idx + 1):\n",
        "                    mapping[char_loc] = (acc, current_token_idx)\n",
        "                acc = \"\"\n",
        "                current_token_idx += 1\n",
        "    \n",
        "    if current_token_idx != len(context_tokens):\n",
        "        return None\n",
        "    else:\n",
        "        return mapping"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aABrBGQ6HZJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_data(filepath):\n",
        "    with open(filepath, 'r') as f:\n",
        "        dataset = json.load(f)\n",
        "    \n",
        "    examples = []\n",
        "    not_matching_answer = 0\n",
        "    not_matching_ans_tokens = 0\n",
        "    num_mapping_prob = 0\n",
        "\n",
        "    for articles_id in range(len(dataset['data'])):\n",
        "        article_paragraphs = dataset['data'][articles_id]['paragraphs']\n",
        "        for pid in range(len(article_paragraphs)):\n",
        "            context = article_paragraphs[pid]['context']\n",
        "            context = context.replace(\"''\", '\" ')\n",
        "            context = context.replace(\"``\", '\" ')\n",
        "            context = context.lower()\n",
        "            context_tokens = tokenize(context)\n",
        "            \n",
        "            qas = article_paragraphs[pid]['qas']\n",
        "\n",
        "            char_to_wordloc = get_char_word_loc_mapping(context, context_tokens)\n",
        "            if char_to_wordloc is None:\n",
        "                num_mapping_prob += len(qas)\n",
        "                continue\n",
        "            \n",
        "            for qa in qas:\n",
        "                question = qa['question']\n",
        "                question_tokens = tokenize(question)\n",
        "\n",
        "                ans_text = qa['answers'][0]['text']\n",
        "                ans_text = ans_text.replace(\"''\", '\" ')\n",
        "                ans_text = ans_text.replace(\"``\", '\" ')\n",
        "                ans_text = ans_text.lower()\n",
        "                ans_start_charloc = qa['answers'][0]['answer_start']\n",
        "                ans_end_charloc = ans_start_charloc + len(ans_text)\n",
        "\n",
        "                if context[ans_start_charloc: ans_end_charloc] != ans_text:\n",
        "                    not_matching_answer += 1\n",
        "                    continue\n",
        "                \n",
        "                ans_start_wordloc = char_to_wordloc[ans_start_charloc][1]\n",
        "                ans_end_wordloc = char_to_wordloc[ans_end_charloc - 1][1]\n",
        "                assert ans_start_wordloc <= ans_end_wordloc, \"Answer indices are not correct\"\n",
        "\n",
        "                ans_tokens = context_tokens[ans_start_wordloc: ans_end_wordloc + 1]\n",
        "                if \"\".join(ans_tokens) != \"\".join(ans_text.lower().split()):\n",
        "                    not_matching_ans_tokens += 1\n",
        "                    continue\n",
        "                \n",
        "                examples.append([context_tokens, question_tokens, ans_tokens, ans_start_wordloc, ans_end_wordloc])\n",
        "\n",
        "    print(f\"Number of  (context, question, answer) triples discarded due to char -> token mapping problems: {num_mapping_prob}\")\n",
        "    print(f\"Number of  (context, question, answer) triples discarded because character-based answer span is unaligned with tokenization: {not_matching_ans_tokens}\")\n",
        "    print(f\"Number of  (context, question, answer) triples discarded due answer span alignment problems: {not_matching_answer}\")\n",
        "\n",
        "    return examples\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkQu7MmhVEsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "2e4b317a-957f-4961-9c4b-b11456638d5b"
      },
      "source": [
        "%%time\n",
        "train_examples = parse_data(train_file)\n",
        "dev_examples = parse_data(dev_file)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of  (context, question, answer) triples discarded due to char -> token mapping problems: 97\n",
            "Number of  (context, question, answer) triples discarded because character-based answer span is unaligned with tokenization: 2521\n",
            "Number of  (context, question, answer) triples discarded due answer span alignment problems: 23\n",
            "Number of  (context, question, answer) triples discarded due to char -> token mapping problems: 0\n",
            "Number of  (context, question, answer) triples discarded because character-based answer span is unaligned with tokenization: 331\n",
            "Number of  (context, question, answer) triples discarded due answer span alignment problems: 0\n",
            "CPU times: user 42.9 s, sys: 261 ms, total: 43.1 s\n",
            "Wall time: 45 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQYScDnSl0IY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d261a66f-460f-4628-83ed-ff5ade50898b"
      },
      "source": [
        "len(train_examples), len(dev_examples)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84958, 10239)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzEMdwMOHeUx",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7x9Ly63Hgcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.idx = 0\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        if not word in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z61x5-FT_fUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(sentences, threshold=50):\n",
        "    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n",
        "    counter = Counter()\n",
        "    for i, sent in enumerate(sentences):\n",
        "        counter.update(sent[0])\n",
        "        counter.update(sent[1])\n",
        "\n",
        "    # If the word frequency is less than 'threshold', then the word is discarded.\n",
        "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
        "\n",
        "    # Create a vocab wrapper and add some special tokens.\n",
        "    vocab = Vocabulary()\n",
        "    vocab.add_word('<pad>')\n",
        "    vocab.add_word('<start>')\n",
        "    vocab.add_word('<end>')\n",
        "    vocab.add_word('<unk>')\n",
        "\n",
        "    # Add the words to the vocabulary.\n",
        "    for i, word in enumerate(words):\n",
        "        vocab.add_word(word)\n",
        "    return vocab"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg6l5EF9VcrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06a022fe-c3bf-4929-f037-96e74d7aba6b"
      },
      "source": [
        "word_vocab = build_vocab(train_examples)\n",
        "print(f\"Length of vocab: {len(word_vocab)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of vocab: 14160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU5tLStXHhMb",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHg5MD2Ts85W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SquadDataset(Dataset):\n",
        "    def __init__(self, examples):\n",
        "        self.examples = examples\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        example = self.examples[item]\n",
        "\n",
        "        context_tokens = example[0]\n",
        "        question_tokens = example[1]\n",
        "        answer_tokens = example[2]\n",
        "        ans_start_idx = example[3]\n",
        "        ans_end_idx = example[4]\n",
        "        ans_span = [ans_start_idx, ans_end_idx]\n",
        "\n",
        "        context_tokens = ['<start>'] + context_tokens + ['<end>']\n",
        "        question_tokens = ['<start>'] + question_tokens + ['<end>']\n",
        "        context_ids = [word_vocab(tok) for tok in context_tokens]\n",
        "        question_ids = [word_vocab(tok) for tok in question_tokens]\n",
        "\n",
        "        return (\n",
        "            torch.LongTensor(context_ids),\n",
        "            context_tokens,\n",
        "            torch.LongTensor(question_ids),\n",
        "            question_tokens,\n",
        "            torch.LongTensor(ans_span),\n",
        "            answer_tokens\n",
        "        )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08106SEc_nBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = SquadDataset(train_examples)\n",
        "dev_dataset = SquadDataset(dev_examples)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOZDUnHpZ-Sf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fea3d305-89dd-40d6-dd37-f691f5429dd5"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  6, 14, 15, 16, 17, 18, 19,\n",
              "          9, 20, 21, 22,  6, 23, 24, 12, 25, 26, 27, 22,  6, 14, 15, 28, 29, 30,\n",
              "          5, 19,  9, 31, 21, 22, 32, 33, 34,  3, 33,  6, 35, 36,  3, 37, 38,  3,\n",
              "         36, 12, 39, 40,  6, 14, 15, 19,  6, 41, 22,  6, 42, 43, 12, 25, 44,  6,\n",
              "         41, 19,  6,  3,  5,  9, 45, 46, 22, 47, 28, 48, 12, 30, 19,  9, 49, 22,\n",
              "          6,  3, 50,  3,  5, 51, 52,  6, 23, 24,  3, 53, 40, 54,  3,  3, 26,  3,\n",
              "         50,  6, 55, 22,  6, 14, 56, 57, 28, 26,  9, 58, 59, 60, 61, 62, 63, 64,\n",
              "         28,  6, 17, 18, 65,  5, 19,  9, 66,  5, 67, 68, 21, 22, 24, 12,  2]),\n",
              " ['<start>',\n",
              "  'architecturally',\n",
              "  ',',\n",
              "  'the',\n",
              "  'school',\n",
              "  'has',\n",
              "  'a',\n",
              "  'catholic',\n",
              "  'character',\n",
              "  '.',\n",
              "  'atop',\n",
              "  'the',\n",
              "  'main',\n",
              "  'building',\n",
              "  \"'s\",\n",
              "  'gold',\n",
              "  'dome',\n",
              "  'is',\n",
              "  'a',\n",
              "  'golden',\n",
              "  'statue',\n",
              "  'of',\n",
              "  'the',\n",
              "  'virgin',\n",
              "  'mary',\n",
              "  '.',\n",
              "  'immediately',\n",
              "  'in',\n",
              "  'front',\n",
              "  'of',\n",
              "  'the',\n",
              "  'main',\n",
              "  'building',\n",
              "  'and',\n",
              "  'facing',\n",
              "  'it',\n",
              "  ',',\n",
              "  'is',\n",
              "  'a',\n",
              "  'copper',\n",
              "  'statue',\n",
              "  'of',\n",
              "  'christ',\n",
              "  'with',\n",
              "  'arms',\n",
              "  'upraised',\n",
              "  'with',\n",
              "  'the',\n",
              "  'legend',\n",
              "  '\"',\n",
              "  'venite',\n",
              "  'ad',\n",
              "  'me',\n",
              "  'omnes',\n",
              "  '\"',\n",
              "  '.',\n",
              "  'next',\n",
              "  'to',\n",
              "  'the',\n",
              "  'main',\n",
              "  'building',\n",
              "  'is',\n",
              "  'the',\n",
              "  'basilica',\n",
              "  'of',\n",
              "  'the',\n",
              "  'sacred',\n",
              "  'heart',\n",
              "  '.',\n",
              "  'immediately',\n",
              "  'behind',\n",
              "  'the',\n",
              "  'basilica',\n",
              "  'is',\n",
              "  'the',\n",
              "  'grotto',\n",
              "  ',',\n",
              "  'a',\n",
              "  'marian',\n",
              "  'place',\n",
              "  'of',\n",
              "  'prayer',\n",
              "  'and',\n",
              "  'reflection',\n",
              "  '.',\n",
              "  'it',\n",
              "  'is',\n",
              "  'a',\n",
              "  'replica',\n",
              "  'of',\n",
              "  'the',\n",
              "  'grotto',\n",
              "  'at',\n",
              "  'lourdes',\n",
              "  ',',\n",
              "  'france',\n",
              "  'where',\n",
              "  'the',\n",
              "  'virgin',\n",
              "  'mary',\n",
              "  'reputedly',\n",
              "  'appeared',\n",
              "  'to',\n",
              "  'saint',\n",
              "  'bernadette',\n",
              "  'soubirous',\n",
              "  'in',\n",
              "  '1858.',\n",
              "  'at',\n",
              "  'the',\n",
              "  'end',\n",
              "  'of',\n",
              "  'the',\n",
              "  'main',\n",
              "  'drive',\n",
              "  '(',\n",
              "  'and',\n",
              "  'in',\n",
              "  'a',\n",
              "  'direct',\n",
              "  'line',\n",
              "  'that',\n",
              "  'connects',\n",
              "  'through',\n",
              "  '3',\n",
              "  'statues',\n",
              "  'and',\n",
              "  'the',\n",
              "  'gold',\n",
              "  'dome',\n",
              "  ')',\n",
              "  ',',\n",
              "  'is',\n",
              "  'a',\n",
              "  'simple',\n",
              "  ',',\n",
              "  'modern',\n",
              "  'stone',\n",
              "  'statue',\n",
              "  'of',\n",
              "  'mary',\n",
              "  '.',\n",
              "  '<end>'],\n",
              " tensor([ 1, 40, 69, 70,  6, 23, 24, 71, 72, 26, 73, 26,  3, 51, 74,  2]),\n",
              " ['<start>',\n",
              "  'to',\n",
              "  'whom',\n",
              "  'did',\n",
              "  'the',\n",
              "  'virgin',\n",
              "  'mary',\n",
              "  'allegedly',\n",
              "  'appear',\n",
              "  'in',\n",
              "  '1858',\n",
              "  'in',\n",
              "  'lourdes',\n",
              "  'france',\n",
              "  '?',\n",
              "  '<end>'],\n",
              " tensor([102, 104]),\n",
              " ['saint', 'bernadette', 'soubirous'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzjrrJkuHn8M",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7citiDrHpeG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    data.sort(key=lambda x: len(x[2]), reverse=True)\n",
        "    context_ids, context_tokens, question_ids, question_tokens, answer_span, answer_tokens = zip(*data)\n",
        "\n",
        "    question_lengths = [len(ques) for ques in question_ids]\n",
        "    context_lengths = [len(context) for context in context_ids]\n",
        "\n",
        "    context_ids_padded = torch.zeros((len(context_ids), max(context_lengths)), dtype=torch.long)\n",
        "    question_ids_padded = torch.zeros((len(question_ids), max(question_lengths)), dtype=torch.long)\n",
        "\n",
        "    for i, sent in enumerate(context_ids):\n",
        "        end = context_lengths[i]\n",
        "        context_ids_padded[i, :end] = sent[:end]\n",
        "    \n",
        "    for i, sent in enumerate(question_ids):\n",
        "        end = question_lengths[i]\n",
        "        question_ids_padded[i, :end] = sent[:end]\n",
        "\n",
        "    questions_mask = (question_ids_padded != 0).long()\n",
        "    contexts_mask = (context_ids_padded != 0).long()\n",
        "    return {\n",
        "        \"question_ids\": question_ids_padded,\n",
        "        \"question_masks\": questions_mask,\n",
        "        \"question_tokens\": question_tokens,\n",
        "        \"context_ids\": context_ids_padded,\n",
        "        \"context_masks\": contexts_mask,\n",
        "        \"context_tokens\": context_tokens,\n",
        "        \"answer_spans\": torch.stack(answer_span),\n",
        "        \"answer_tokens\": answer_tokens\n",
        "    }"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZz2GHaaaDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
        "dev_data_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvZ24fETbVbJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "23203840-3abe-4708-d500-23e7b373775d"
      },
      "source": [
        "sample = next(iter(train_data_loader))\n",
        "sample['question_ids'].shape, sample['question_masks'].shape, sample['context_ids'].shape, sample['context_masks'].shape, sample['answer_spans'].shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 41]),\n",
              " torch.Size([128, 41]),\n",
              " torch.Size([128, 398]),\n",
              " torch.Size([128, 398]),\n",
              " torch.Size([128, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcAqf4vaHqz1",
        "colab_type": "text"
      },
      "source": [
        "## Double Cross Attention Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o69fLv8lHxhh",
        "colab_type": "text"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-id4KJAsyZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.encoder = nn.LSTM(emb_dim, hidden_dim, batch_first=True, num_layers=1, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, input, input_mask):\n",
        "        # input => [batch_size, seq_len]\n",
        "        # input_mask => [batch_size, seq_len]\n",
        "\n",
        "        input_lengths = torch.sum(input_mask, 1)\n",
        "        sorted_lengths, sorted_lengths_index = torch.sort(input_lengths, 0, True)\n",
        "        _, original_index = torch.sort(sorted_lengths_index, 0)\n",
        "\n",
        "        # arrange input according to descending length\n",
        "        input_sorted = torch.index_select(input, 0, sorted_lengths_index)\n",
        "        input_embed = self.embedding(input_sorted)\n",
        "        input_embed = self.dropout(input_embed)\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(input_embed, sorted_lengths, batch_first=True)\n",
        "        output, _ = self.encoder(packed_input)\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
        "        output = output.contiguous()\n",
        "\n",
        "        # rearrange the output to it's original order\n",
        "        output = torch.index_select(output, 0, original_index)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzT-lfyfHzeV",
        "colab_type": "text"
      },
      "source": [
        "### CoAttention Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSyG95Fa09_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CoAttentionEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.encoder_dq = Encoder(input_dim, emb_dim, hidden_dim, dropout)\n",
        "        \n",
        "        self.q_proj = nn.Linear(2 * hidden_dim, 2 * hidden_dim)\n",
        "        self.fusion_lstm = nn.LSTM(6 * hidden_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, question, question_mask, document, document_mask):\n",
        "        # question => [batch_size, ques_len]\n",
        "        # question_mask => [batch_size, ques_len]\n",
        "        # document => [batch_size, doc_len]\n",
        "        # document_mask => [batch_size, doc_len]\n",
        "\n",
        "        Q = self.encoder_dq(question, question_mask)\n",
        "        # Q => [batch_size, ques_len, hidden_dim * 2]\n",
        "        C = self.encoder_dq(document, document_mask)\n",
        "        # C => [batch_size, doc_len, hidden_dim * 2]\n",
        "\n",
        "        Q = torch.tanh(self.q_proj(Q.view(-1, 2 * hidden_dim)).view(Q.size()))\n",
        "        # Q => [batch_size, ques_len, hidden_dim * 2]\n",
        "\n",
        "        S = torch.bmm(Q, C.transpose(1, 2))\n",
        "        # Q   => [batch_size, ques_len, hid_dim * 2]\n",
        "        # C_t => [batch_size, hid_dim * 2, doc_len]\n",
        "        # S   => [batch_size, ques_len, doc_len]\n",
        "\n",
        "        A_Q = F.softmax(S, dim=1)\n",
        "        # A_Q => [batch_size, ques_len, doc_len]\n",
        "        C2Q = torch.bmm(A_Q.transpose(1, 2), Q)\n",
        "        # A_Q_t => [batch_size, doc_len, ques_len]\n",
        "        # Q     => [batch_size, ques_len, hid_dim * 2]\n",
        "        # C2Q   => [batch_size, doc_len, hid_dim * 2]\n",
        "\n",
        "        A_C = F.softmax(S, dim=2)\n",
        "        # A_C => [batch_size, ques_len, doc_len]\n",
        "        Q2C = torch.bmm(A_C, C)\n",
        "        # A_C => [batch_size, ques_len, doc_len]\n",
        "        # C   => [batch_size, doc_len, hid_dim * 2]\n",
        "        # Q2C => [batch_size, ques_len, hid_dim * 2]\n",
        "\n",
        "        R = torch.bmm(Q2C, C2Q.transpose(1, 2))\n",
        "        # Q2C   => [batch_size, ques_len, hid_dim * 2]\n",
        "        # C2Q_t => [batch_size, hid_dim * 2, doc_len]\n",
        "        # R     => [batch_size, ques_len, doc_len]\n",
        "\n",
        "        gamma = F.softmax(R, dim=1)\n",
        "        # gamma => [batch_size, ques_len, doc_len]\n",
        "        CA2QA = torch.bmm(gamma.transpose(1, 2), Q2C)\n",
        "        # gamma_t => [batch_size, doc_len, ques_len]\n",
        "        # Q2C     => [batch_size, ques_len, hid_dim * 2]\n",
        "        # CA2QA   => [batch_size, doc_len, hid_dim * 2]\n",
        "\n",
        "        input_bilstm = torch.cat((C, C2Q, CA2QA), dim=2)\n",
        "        input_bilstm = self.dropout(input_bilstm)\n",
        "        # input_bilstm => [batch_size, doc_len, hid_dim * 6]\n",
        "\n",
        "        doc_lengths = torch.sum(document_mask, 1)\n",
        "        sorted_doc_lengths, sorted_doc_lengths_index = torch.sort(doc_lengths, descending=True)\n",
        "        _, doc_original_index = torch.sort(sorted_doc_lengths_index)\n",
        "        sorted_docs = torch.index_select(input_bilstm, 0, sorted_doc_lengths_index)\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(sorted_docs, sorted_doc_lengths, batch_first=True)\n",
        "        output, _ = self.fusion_lstm(packed_input)\n",
        "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
        "        output = output.contiguous()\n",
        "        output = torch.index_select(output, 0, doc_original_index)\n",
        "        output = self.dropout(output)\n",
        "        # output => [batch_size, doc_len, hid_dim * 2]\n",
        "\n",
        "        return output"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umR4XfZUH2Ob",
        "colab_type": "text"
      },
      "source": [
        "### Highway Maxout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziu9wxRu043O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HighwayMaxoutModel(nn.Module):\n",
        "    def __init__(self, hidden_dim, pool_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "        self.f_r = nn.Linear(5 * hidden_dim, hidden_dim, bias=False)\n",
        "        self.f_m_1 = nn.Linear(3 * hidden_dim, pool_size * hidden_dim)\n",
        "        self.f_m_2 = nn.Linear(hidden_dim, pool_size * hidden_dim)\n",
        "        self.f_final = nn.Linear(2 * hidden_dim, pool_size)\n",
        "        self.loss = nn.CrossEntropyLoss(reduction='none')\n",
        "        \n",
        "    def forward(self, doc_encoded, doc_mask, loss_mask, old_idx, hidden_state, u_s, u_e, target=None):\n",
        "        # doc_encoded => [batch_size, doc_len, hid_dim * 2]\n",
        "        # doc_mask => [batch_size, doc_len]\n",
        "        # loss_mask => [batch_size, doc_len]\n",
        "        # old_idx => [batch_size]\n",
        "        # hidden_state => [batch_size, hid_dim]\n",
        "        # u_s, u_e => [batch_size, hid_dim * 2]\n",
        "        # target => [batch_size]\n",
        "\n",
        "        batch_size, doc_len, _ = list(doc_encoded.size())\n",
        "\n",
        "        r = torch.tanh(self.f_r(torch.cat((hidden_state, u_s, u_e), dim=1)))\n",
        "        # r => [batch_size, hid_dim]\n",
        "        r = r.unsqueeze(1)\n",
        "        # r => [batch_size, 1, hid_dim]\n",
        "        r = r.expand(batch_size, doc_len, -1).contiguous()\n",
        "        # r => [batch_size, doc_len, hid_dim]\n",
        "\n",
        "        highway_input = torch.cat((doc_encoded, r), dim=2).view(-1, 3 * self.hidden_dim)\n",
        "        # highway_input => [batch_size * doc_len, 3 * hidden_dim]\n",
        "        m_1 = self.f_m_1(highway_input)\n",
        "        # m_1 => [batch_size * doc_len, hidden_dim * pool_size]\n",
        "        m_1 = m_1.view(batch_size, doc_len, self.pool_size, self.hidden_dim)\n",
        "        # m_1 => [batch_size, doc_len, pool_size, hidden_dim]\n",
        "        m_1, _ = torch.max(m_1, 2)\n",
        "        # m_1 => [batch_size, doc_len, hidden_dim]\n",
        "\n",
        "        m_2 = self.f_m_2(m_1.view(-1, self.hidden_dim))\n",
        "        # m_2 => [batch_size * doc_len, hidden_dim * pool_size]\n",
        "        m_2 = m_2.view(batch_size, doc_len, self.pool_size, self.hidden_dim)\n",
        "        m_2, _ = torch.max(m_2, 2)\n",
        "        # m_2 => [batch_size, doc_len, hidden_dim]\n",
        "\n",
        "        final_input = torch.cat((m_1, m_2), dim=2)\n",
        "        # final_input => [batch_size, doc_len, hid_dim * 2]\n",
        "        final_input = final_input.view(-1, self.hidden_dim * 2)\n",
        "        # final_input => [batch_size * doc_len, hid_dim * 2]\n",
        "        output = self.f_final(final_input)\n",
        "        # output => [batch_size * doc_len, pool_size]\n",
        "        output = output.view(batch_size, doc_len, self.pool_size)\n",
        "        # output => [batch_size, doc_len, pool_size]\n",
        "        output, _ = torch.max(output, 2)\n",
        "        # output => [batch_size, doc_len]\n",
        "\n",
        "        output = output + doc_mask\n",
        "        # output => [batch_size, doc_len]\n",
        "        _, idx_output = torch.max(output, 1)\n",
        "        # idx_output => [batch_size]\n",
        "\n",
        "        # Eliminate unnecessary loss values\n",
        "        if loss_mask is None:\n",
        "            loss_mask = (idx_output == idx_output)\n",
        "        else:\n",
        "            old_idx_ = old_idx * loss_mask.long()\n",
        "            idx_output_ = idx_output * loss_mask.long()\n",
        "            loss_mask = (old_idx_ != idx_output_)\n",
        "        \n",
        "        loss = None\n",
        "        # Calculate the loss\n",
        "        if target is not None:\n",
        "            scores = F.log_softmax(output, 1)\n",
        "            loss = self.loss(scores, target)\n",
        "            loss = loss * loss_mask.float()\n",
        "        \n",
        "        return idx_output, loss_mask, loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGod6STqH52e",
        "colab_type": "text"
      },
      "source": [
        "### Dynamic Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq8otoYN01iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynamicDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, pool_size, max_iter, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.max_iter = max_iter\n",
        "        \n",
        "        self.decoder = nn.LSTM(4 * hidden_dim, hidden_dim, num_layers=1, batch_first=True)\n",
        "        self.hmn_s = HighwayMaxoutModel(hidden_dim, pool_size)\n",
        "        self.hmn_e = HighwayMaxoutModel(hidden_dim, pool_size)\n",
        "    \n",
        "    def forward(self, doc_encoded, doc_mask, ans_span):\n",
        "        # doc_encoded => [batch_size, doc_len, hid_dim * 2]\n",
        "        # doc_mask => [batch_size, doc_len]\n",
        "        # ans_span => [batch_size, 2]\n",
        "\n",
        "        batch_size, doc_len, _ = list(doc_encoded.size())\n",
        "\n",
        "        # Initialize start to be the first word and end to be the last word\n",
        "        s = torch.zeros(batch_size).long().to(device)\n",
        "        e = torch.sum(doc_mask, 1) - 1\n",
        "        e = e.to(device)\n",
        "\n",
        "        indices = torch.arange(0, batch_size).long().to(device)\n",
        "        # To make choosing impossible in HighwayMaxout\n",
        "        mask_hmn = (1 - doc_mask).float() * -1e15\n",
        "\n",
        "        target_s, target_e = None, None\n",
        "        if ans_span is not None:\n",
        "            target_s = ans_span[:, 0]\n",
        "            target_e = ans_span[:, 1]\n",
        "            # target_* => [batch_size]\n",
        "        \n",
        "        lstm_states = None\n",
        "        losses = []\n",
        "\n",
        "        for _ in range(self.max_iter):\n",
        "            u_s = doc_encoded[indices, s, :]\n",
        "            u_e = doc_encoded[indices, e, :]\n",
        "            # u_* => [batch_size, hid_dim * 2]\n",
        "\n",
        "            combined_input = torch.cat((u_s, u_e), dim=1)\n",
        "            # combined_input => [batch_size, hid_dim * 4]\n",
        "            combined_input = combined_input.unsqueeze(1)\n",
        "            # combined_input => [batch_size, 1, hid_dim * 4]\n",
        "\n",
        "            _, lstm_states = self.decoder(combined_input, lstm_states)\n",
        "            hidden_state, _ = lstm_states\n",
        "            # hidden_state => [num_layers * num_dir, batch_size, hid_dim]\n",
        "            hidden_state = hidden_state.view(-1, self.hidden_dim)\n",
        "            # hidden_state => [batch_size, hid_dim]\n",
        "\n",
        "            loss_mask_s, loss_mask_e = None, None\n",
        "\n",
        "            s_new, loss_mask_s, loss_s = self.hmn_s(doc_encoded, mask_hmn, loss_mask_s, s, hidden_state, u_s, u_e, target_s)\n",
        "            e_new, loss_mask_e, loss_e = self.hmn_e(doc_encoded, mask_hmn, loss_mask_e, e, hidden_state, u_s, u_e, target_e)\n",
        "\n",
        "            if ans_span is not None:\n",
        "                losses.append(loss_s + loss_e)\n",
        "            \n",
        "            if torch.sum(s_new != s).item() == 0 and torch.sum(e_new != e).item() == 0:\n",
        "                s = s_new\n",
        "                e = e_new\n",
        "                break\n",
        "            \n",
        "            s = s_new\n",
        "            e = e_new\n",
        "        \n",
        "        cumulative_loss = None\n",
        "\n",
        "        if ans_span is not None:\n",
        "            cumulative_loss = torch.sum(torch.stack(losses, 1), 1)\n",
        "            cumulative_loss = cumulative_loss / self.max_iter\n",
        "            cumulative_loss = torch.mean(cumulative_loss)\n",
        "        \n",
        "        return s, e, cumulative_loss"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT8ZY39EH8cC",
        "colab_type": "text"
      },
      "source": [
        "### DCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4WVNHvLcO4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCAModel(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hidden_dim, pool_size, max_iter, dropout=0.4):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = CoAttentionEncoder(input_dim, emb_dim, hidden_dim, dropout)\n",
        "        self.decoder = DynamicDecoder(hidden_dim, pool_size, max_iter, dropout)\n",
        "    \n",
        "    def forward(self, question, question_mask, document, document_mask, ans_span=None):\n",
        "        U = self.encoder(question, question_mask, document, document_mask)\n",
        "        s, e, loss = self.decoder(U, document_mask, ans_span)\n",
        "        if ans_span is not None:\n",
        "            return loss, s, e\n",
        "        else:\n",
        "            return s, e\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHrLacKrH-K-",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kTT0rdyH-33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(word_vocab)\n",
        "emb_dim = 100\n",
        "hidden_dim = 200\n",
        "pool_size = 16\n",
        "max_dec_steps = 4\n",
        "\n",
        "model = DCAModel(input_dim, emb_dim, hidden_dim, pool_size, max_dec_steps)\n",
        "model = model.to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9aZnEy4dCnF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c75f16ba-81d4-4f71-bb67-c308585458d4"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 10,650,032 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FucvadDuH_hj",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt_7c3uaIBIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "min_lr = 3e-5\n",
        "lr_decay=0.5\n",
        "lr_patience=2\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', lr_decay, lr_patience, verbose=True, min_lr=min_lr)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmmGQepqIB_R",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJqLuq_yID5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(iterator, clip=2.0):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        question_ids = batch['question_ids'].to(device)\n",
        "        question_masks = batch['question_masks'].to(device)\n",
        "        document_ids = batch['context_ids'].to(device)\n",
        "        document_masks = batch['context_masks'].to(device)\n",
        "        ans_span = batch['answer_spans'].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + loss\n",
        "        loss, start_logits, end_logits = model(question_ids, question_masks, document_ids, document_masks, ans_span)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnLaYxvwIEoA",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUpmIonlIGOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(iterator):\n",
        "    epoch_loss = 0\n",
        "    model.eval()\n",
        "    epoch_f1, epoch_em = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            question_ids = batch['question_ids'].to(device)\n",
        "            question_masks = batch['question_masks'].to(device)\n",
        "            document_ids = batch['context_ids'].to(device)\n",
        "            document_masks = batch['context_masks'].to(device)\n",
        "            ans_span = batch['answer_spans'].to(device)\n",
        "\n",
        "            # forward  + loss\n",
        "            loss, start_logits, end_logits = model(question_ids, question_masks, document_ids, document_masks, ans_span)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # f1 + em\n",
        "            # TODO\n",
        "    return epoch_loss / len(iterator) #, epoch_f1 / len(iterator), epoch_em / len(iterator)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPPi68UmeZx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = elapsed_time - (elapsed_mins * 60)\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abfffzq5IGv8",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTljcB0xIHxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "778d68f6-3696-4dc1-af58-e566c1b98e0e"
      },
      "source": [
        "NUM_EPOCHS = 2\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(train_data_loader)\n",
        "    val_loss = evaluate(dev_data_loader)\n",
        "    end_time = time.time()\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    print(f\"Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f}\")\n",
        "    \n",
        "    if val_loss < best_valid_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 50m 2.92s\n",
            "\tTrain Loss: 9.721 | Val Loss: 9.770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo3XAg61x3yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
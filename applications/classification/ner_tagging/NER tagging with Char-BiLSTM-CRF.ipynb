{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER tagging with Char-BiLSTM-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2haF4Hn2kRNz",
        "vIFVl-O_kUJb",
        "RBVQHwTVk88N",
        "wwiiGscn29-V",
        "1Fpc9vWq3EY3",
        "zv1kwAoG3IzE",
        "TeoX6uxx3MVe",
        "5urAtI4W3OUf",
        "TIXBCe7S3c3y"
      ],
      "authorship_tag": "ABX9TyMjKxJ/psQHWaURzVC6BFP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/applications%2Fclassification/applications/classification/ner_tagging/NER%20tagging%20with%20Char-BiLSTM-CRF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeK9dZJmkDQg",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5jkJpQvdgjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "00c55838-1924-4766-c367-c5ab46d5c219"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5eEi8pCZYYu",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ba11e5f4-858c-4143-abc3-e16c52903514"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95553c33-949c-4ffa-9020-72d1f7c71445\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95553c33-949c-4ffa-9020-72d1f7c71445\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ravirajag\",\"key\":\"7c9b32c3baf1bd5e404db6e4e281fc5c\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBOvFvrBdm1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKDfern7eAi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ff9eb42d-5417-454e-d817-c644b6a4d75b"
      },
      "source": [
        "!kaggle datasets download -d abhinavwalia95/entity-annotated-corpus"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading entity-annotated-corpus.zip to /content\n",
            " 64% 17.0M/26.4M [00:00<00:00, 23.9MB/s]\n",
            "100% 26.4M/26.4M [00:00<00:00, 36.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1LvqrEIeFvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c6d5b0b9-9a4b-42da-a9d6-38aa037c5247"
      },
      "source": [
        "!unzip entity-annotated-corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  entity-annotated-corpus.zip\n",
            "  inflating: ner.csv                 \n",
            "  inflating: ner_dataset.csv         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuSoeUl3kFz2",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD_gnl5YQHEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "85799ce8-18f0-44fe-91bc-061f3620bc4c"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from itertools import chain\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NemuvQdVpGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51483814-fba7-4b3a-d485-0e8afe028775"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNeeukPGkLSC",
        "colab_type": "text"
      },
      "source": [
        "### Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1ADdqCeRcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafile = 'ner_dataset.csv'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXIfU9fBfB6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
        "df = df.fillna(method='ffill')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T1WOTYVfRLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4a82111b-998a-4c71-ce1b-1aa48c5f47fa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAzzVjPqf7Lb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a92aecc-cf59-4e7c-d460-5d41797d6495"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1048575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c16vzijfkwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "55eecbe2-f95c-4ca0-a94c-45dfd5c39f78"
      },
      "source": [
        "tags = list(df.Tag.unique())\n",
        "tags"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-per',\n",
              " 'I-geo',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'B-tim',\n",
              " 'B-art',\n",
              " 'I-art',\n",
              " 'I-per',\n",
              " 'I-gpe',\n",
              " 'I-tim',\n",
              " 'B-nat',\n",
              " 'B-eve',\n",
              " 'I-eve',\n",
              " 'I-nat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eKeAR8DftPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "87d64dc0-7979-48fb-bc1d-b560b26330b4"
      },
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(df.Tag.values)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1d20c269e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPDMLtKdhFrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fab11c77-9f0a-4f2f-beae-30362f088329"
      },
      "source": [
        "num_tags = len(tags)\n",
        "num_tags"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2haF4Hn2kRNz",
        "colab_type": "text"
      },
      "source": [
        "### Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmI25jJhjLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
        "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
        "lines = [s for s in group]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RknB-LoUiATn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "f1911ed9-0fb3-43d4-be94-12889caa9d7c"
      },
      "source": [
        "lines[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'O'),\n",
              " ('of', 'O'),\n",
              " ('demonstrators', 'O'),\n",
              " ('have', 'O'),\n",
              " ('marched', 'O'),\n",
              " ('through', 'O'),\n",
              " ('London', 'B-geo'),\n",
              " ('to', 'O'),\n",
              " ('protest', 'O'),\n",
              " ('the', 'O'),\n",
              " ('war', 'O'),\n",
              " ('in', 'O'),\n",
              " ('Iraq', 'B-geo'),\n",
              " ('and', 'O'),\n",
              " ('demand', 'O'),\n",
              " ('the', 'O'),\n",
              " ('withdrawal', 'O'),\n",
              " ('of', 'O'),\n",
              " ('British', 'B-gpe'),\n",
              " ('troops', 'O'),\n",
              " ('from', 'O'),\n",
              " ('that', 'O'),\n",
              " ('country', 'O'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJvFI3yqgi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END>'] for line in lines]\n",
        "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END>'] for line in lines]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Q6hAx4SU22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = [[['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in sent[1:-1]] + [['<END>']] for sent in sentences]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0xItc3iFhX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7830059-2ed4-40d3-e23c-5efc8c654b81"
      },
      "source": [
        "len(sentences), len(tags), len(chars)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47959, 47959, 47959)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u29TiWBiSQuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "5a6f8e3f-164a-4ef8-ae5f-477f5934584b"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<START>',\n",
              " 'Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.',\n",
              " '<END>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1jcQSbGStyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "fa187590-1441-4c0d-bb0c-3d9e510afd98"
      },
      "source": [
        "chars[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['<START'],\n",
              " ['<START>', 'T', 'h', 'o', 'u', 's', 'a', 'n', 'd', 's', '<END>'],\n",
              " ['<START>', 'o', 'f', '<END>'],\n",
              " ['<START>',\n",
              "  'd',\n",
              "  'e',\n",
              "  'm',\n",
              "  'o',\n",
              "  'n',\n",
              "  's',\n",
              "  't',\n",
              "  'r',\n",
              "  'a',\n",
              "  't',\n",
              "  'o',\n",
              "  'r',\n",
              "  's',\n",
              "  '<END>'],\n",
              " ['<START>', 'h', 'a', 'v', 'e', '<END>'],\n",
              " ['<START>', 'm', 'a', 'r', 'c', 'h', 'e', 'd', '<END>'],\n",
              " ['<START>', 't', 'h', 'r', 'o', 'u', 'g', 'h', '<END>'],\n",
              " ['<START>', 'L', 'o', 'n', 'd', 'o', 'n', '<END>'],\n",
              " ['<START>', 't', 'o', '<END>'],\n",
              " ['<START>', 'p', 'r', 'o', 't', 'e', 's', 't', '<END>'],\n",
              " ['<START>', 't', 'h', 'e', '<END>'],\n",
              " ['<START>', 'w', 'a', 'r', '<END>'],\n",
              " ['<START>', 'i', 'n', '<END>'],\n",
              " ['<START>', 'I', 'r', 'a', 'q', '<END>'],\n",
              " ['<START>', 'a', 'n', 'd', '<END>'],\n",
              " ['<START>', 'd', 'e', 'm', 'a', 'n', 'd', '<END>'],\n",
              " ['<START>', 't', 'h', 'e', '<END>'],\n",
              " ['<START>', 'w', 'i', 't', 'h', 'd', 'r', 'a', 'w', 'a', 'l', '<END>'],\n",
              " ['<START>', 'o', 'f', '<END>'],\n",
              " ['<START>', 'B', 'r', 'i', 't', 'i', 's', 'h', '<END>'],\n",
              " ['<START>', 't', 'r', 'o', 'o', 'p', 's', '<END>'],\n",
              " ['<START>', 'f', 'r', 'o', 'm', '<END>'],\n",
              " ['<START>', 't', 'h', 'a', 't', '<END>'],\n",
              " ['<START>', 'c', 'o', 'u', 'n', 't', 'r', 'y', '<END>'],\n",
              " ['<START>', '.', '<END>'],\n",
              " ['<END>']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH_xnhJFkj1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "79554a77-1ca7-4eea-9a57-74e46a108169"
      },
      "source": [
        "sen_lengths = [len(sent) for sent in sentences]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(sen_lengths)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1d09780080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4b87TebTsen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "4536c243-419e-421f-871e-3fe3bf777ec1"
      },
      "source": [
        "char_lengths = [len(t) for char in chars for t in char]\n",
        "plt.figure(figsize=(15, 5))\n",
        "sns.countplot(char_lengths)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f1fae95c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5HlzOzGmEDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bff0c5dc-74bf-4ec6-ddf7-1c7d1fe32fc0"
      },
      "source": [
        "train_sentences, valid_sentences, train_tags, valid_tags, train_chars, valid_chars = train_test_split(sentences, tags, chars, test_size=0.2, random_state=42)\n",
        "valid_sentences, test_sentences, valid_tags, test_tags, valid_chars, test_chars = train_test_split(valid_sentences, valid_tags, valid_chars, test_size=0.5, random_state=42)\n",
        "len(train_sentences), len(valid_sentences), len(test_sentences)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38367, 4796, 4796)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIFVl-O_kUJb",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9eJdmdhoamw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self, word2id, id2word):\n",
        "        self.UNK = '<UNK>'\n",
        "        self.PAD = '<PAD>'\n",
        "        self.START = '<START>'\n",
        "        self.END = '<END>'\n",
        "        self.__word2id = word2id\n",
        "        self.__id2word = id2word\n",
        "\n",
        "    def get_word2id(self):\n",
        "        return self.__word2id\n",
        "\n",
        "    def get_id2word(self):\n",
        "        return self.__id2word\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        if self.UNK in self.__word2id:\n",
        "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
        "        return self.__word2id[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__word2id)\n",
        "\n",
        "    def id2word(self, idx):\n",
        "        return self.__id2word[idx]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YlwfEdHocqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(data, freq_cutoff=5, is_tags=False, is_chars=False):\n",
        "    if is_chars:\n",
        "        word_counts = Counter(chain(*chain(*train_chars[:10])))\n",
        "    else:\n",
        "        word_counts = Counter(chain(*data))\n",
        "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
        "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
        "    valid_words += ['<PAD>']\n",
        "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
        "    if not is_tags:\n",
        "        word2id['<UNK>'] = len(word2id)\n",
        "        valid_words += ['<UNK>']\n",
        "    return Vocab(word2id=word2id, id2word=valid_words)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzicTNXdj8Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_vocab = build_vocab(train_sentences)\n",
        "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
        "chars_vocab = build_vocab(train_chars, is_chars=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2LrPT8HUvHB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e4818a7-5f0f-4473-dcfa-680760604bc6"
      },
      "source": [
        "len(words_vocab), len(tags_vocab), len(chars_vocab)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9620, 20, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBVQHwTVk88N",
        "colab_type": "text"
      },
      "source": [
        "### NER Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3RhXjbdk_Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LEN = 50\n",
        "MAX_WORD_LEN = 15"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToE09rDqx8Bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NERDataset(data.Dataset):\n",
        "    def __init__(self, sentences, tags, chars, max_seq_len, max_word_len):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.characters = chars\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.max_word_len = max_word_len\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        sentence = self.sentences[item]\n",
        "        tag = self.tags[item]\n",
        "        chars = self.characters[item]\n",
        "        seq_len = len(sentence)\n",
        "\n",
        "        # convert the sentences and tags into numerical format\n",
        "        word_tokens = [words_vocab[word] for word in sentence]\n",
        "        tag_tokens = [tags_vocab[t] for t in tag]\n",
        "\n",
        "        char_seq = []\n",
        "        for word in chars:\n",
        "            word_len = len(word)\n",
        "            # truncate the word if it is greater than max_word_len\n",
        "            if word_len > self.max_word_len:\n",
        "                word = word[:self.max_word_len]\n",
        "            # pad the word if it less\n",
        "            else:\n",
        "                pad_length = self.max_word_len - word_len\n",
        "                word = word + [chars_vocab.PAD] * pad_length\n",
        "            \n",
        "            # convert the chars into numerical format\n",
        "            char_ids = []\n",
        "            for each_char in word: \n",
        "                char_ids.append(chars_vocab[each_char])\n",
        "            char_seq.append(char_ids)\n",
        "        \n",
        "        return torch.LongTensor(word_tokens), torch.LongTensor(char_seq), torch.LongTensor(tag_tokens)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPJmCn-VyQDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = NERDataset(train_sentences, train_tags, train_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
        "valid_dataset = NERDataset(valid_sentences, valid_tags, valid_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
        "test_dataset = NERDataset(test_sentences, test_tags, test_chars, MAX_SEQ_LEN, MAX_WORD_LEN)"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cFfg0IqFE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5875968b-3815-48c6-fd19-49e49a711a83"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([   1,  150,  235,   11,   36,   72,   49, 3318,    8, 1977, 4171,  166,\n",
              "         9619, 9619, 7832,    4,  199,    7, 1385, 9619,   67, 1103,    3,    2]),\n",
              " tensor([[24, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 28,  4, 14,  5, 11,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4,  6,  2,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 29,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 16,  4, 21,  2,  6,  8, 15,  2,  8,  5,  0, 32, 32, 32],\n",
              "         [ 1, 33, 14,  2,  7, 10,  3, 19,  0, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  3, 12,  7,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 14,  8, 21,  2,  9, 12,  2, 10,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  7,  4, 33, 13,  3, 12, 12,  2, 10,  0, 32, 32, 32, 32],\n",
              "         [ 1, 33,  6,  2,  2,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4, 26,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  6,  2,  3,  5,  9,  4,  8,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33, 12,  3,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 25,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1,  2, 33, 18,  2, 13,  5,  2, 10,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  5,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 13,  6,  2,  3,  5,  2,  0, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33, 25, 33, 22, 25, 22, 22, 22,  0, 32, 32, 32, 32, 32],\n",
              "         [ 1,  8,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 33,  4, 26,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 1, 20,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
              "         [ 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]]),\n",
              " tensor([ 1,  3, 10,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwiiGscn29-V",
        "colab_type": "text"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGPqxgEboFV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpHqwpKNqtcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_fn(data):\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "    sentences, words, tags = zip(*data)\n",
        "\n",
        "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
        "    sent_lengths = [len(sent) for sent in sentences]\n",
        "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
        "    chars = torch.zeros(len(sentences), max(sent_lengths), MAX_WORD_LEN).long()\n",
        "    for i, (sent, lab, ch) in enumerate(zip(sentences, tags, words)):\n",
        "        end = sent_lengths[i]\n",
        "        inputs[i, :end] = sent[:end]\n",
        "        labels[i, :end] = lab[:end]\n",
        "        chars[i, :end] = ch[:end]\n",
        "    return inputs, chars, labels, sent_lengths\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_hY3a7DyhKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHLq_P4n3AT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = next(iter(train_data_loader))"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWf2QvFsgT3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28c298fb-9814-4109-e375-d7c983aace04"
      },
      "source": [
        "sample[0].shape, sample[1].shape, sample[2].shape, len(sample[3])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 43]), torch.Size([64, 43, 15]), torch.Size([64, 43]), 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q08pzQGp3Ami",
        "colab_type": "text"
      },
      "source": [
        "### Charcter-BiLSTM-CRF Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFzphEAGTxad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharBiLSTMCRF(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, char_emb_dim, char_hid_dim, char_vocab_size, tag_vocab_size, sent_pad_token, tag_start_token, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.sent_pad_token = sent_pad_token\n",
        "        self.tag_start_token = tag_start_token\n",
        "        self.tag_vocab_size = tag_vocab_size\n",
        "\n",
        "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
        "        self.char_lstm = nn.LSTM(char_emb_dim, char_hid_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim + char_hid_dim,\n",
        "            hid_dim,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.emission = nn.Linear(hid_dim * 2, tag_vocab_size)\n",
        "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "    def forward(self, sentences, lengths, words, tags):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        char_final_hidden = []\n",
        "        for word in words:\n",
        "            # word => [seq_len, word_len]\n",
        "            char_embed = self.char_embedding(word)\n",
        "            char_embed = self.dropout(char_embed)\n",
        "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
        "\n",
        "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
        "            # char_hidden => [2, seq_len, char_hid_dim]\n",
        "\n",
        "            # add the final forward and backward hidden states\n",
        "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
        "            # char_combined => [seq_len, char_hid_dim]\n",
        "\n",
        "            char_final_hidden.append(char_combined)\n",
        "        \n",
        "        char_encoding = torch.stack(char_final_hidden)\n",
        "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
        "\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
        "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
        "\n",
        "        packed_input = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_input)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
        "        # loss => [batch_size]\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def vitebri_loss(self, tags, mask, emit_scores):\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # mask => [batch_size, seq_len]\n",
        "        # emit_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        batch_size, sent_len = tags.shape\n",
        "\n",
        "        # calculate the ground truth score\n",
        "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
        "        # emission scores of actual tags\n",
        "        # score => [batch_size, seq_len]\n",
        "\n",
        "        # add the transition scores to the emission scores\n",
        "        # ignore the start token tag score\n",
        "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
        "\n",
        "        # consider only the scores of actual tokens not the padded\n",
        "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
        "        # gold_scores => [batch_size]\n",
        "\n",
        "        # calculate the scores of the partition (Z)\n",
        "        # tensor to hold the accumulated sequence scores at each time step\n",
        "        # at the inital time step score will be on dim=0\n",
        "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, sent_len):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "            \n",
        "            # apply the following to overcome the overflow problems\n",
        "            # since the exp(some_big_number) will cause issues \n",
        "            # log(Σ exp(z_k)) = max(z) + log(Σ exp(z_k - max(z)))\n",
        "            # log(Σ exp(z_k)) = log(Σ exp(z_k - c + c))\n",
        "            #                 = log(Σ exp(z_k - c) * exp(c))\n",
        "            #                 = log(Σ exp(z_k - c)) + log(exp(c))\n",
        "            #                 = log(Σ exp(z_k - c)) + c\n",
        "            # by taking c as max(z)\n",
        "            # log(Σ exp(z_k)) = max(z) + log(Σ exp(z_k - max(z))) [log_sum_exp]\n",
        "            # get the maximum score of the current time step\n",
        "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
        "            # max_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            sum_scores = sum_scores - max_t\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
        "            # scores_t => [batch_t, 1, tag_size]\n",
        "\n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, 1, tag_size]\n",
        "        \n",
        "        final_scores = scores_upto_t.squeeze(1)\n",
        "        # final_scores => [batch_size, tag_size]\n",
        "\n",
        "        max_final_scores = final_scores.max(dim=-1)[0]\n",
        "        # max_final_scores => [batch_size]\n",
        "\n",
        "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
        "        # predicted_scores => [batch_size]\n",
        "\n",
        "        vitebri_loss = predicted_scores - gold_scores\n",
        "        # vitebri_loss => [batch_size]\n",
        "\n",
        "        return vitebri_loss\n",
        "    \n",
        "    def predict(self, sentences, lengths, words):\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # lengths => [batch_size]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "\n",
        "        batch_size = sentences.size(0)\n",
        "\n",
        "        char_final_hidden = []\n",
        "        for word in words:\n",
        "            # word => [seq_len, word_len]\n",
        "            char_embed = self.char_embedding(word)\n",
        "            char_embed = self.dropout(char_embed)\n",
        "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
        "\n",
        "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
        "            # char_hidden => [2, seq_len, char_hid_dim]\n",
        "\n",
        "            # add the final forward and backward hidden states\n",
        "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
        "            # char_combined => [seq_len, char_hid_dim]\n",
        "\n",
        "            char_final_hidden.append(char_combined)\n",
        "        \n",
        "        char_encoding = torch.stack(char_final_hidden)\n",
        "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
        "\n",
        "        mask = (sentences != self.sent_pad_token).to(device)\n",
        "        # mask => [batch_size, seq_len]\n",
        "\n",
        "        embed = self.embedding(sentences)\n",
        "        embed = self.dropout(embed)\n",
        "        # embed => [batch_size, seq_len, emb_dim]\n",
        "\n",
        "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
        "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
        "\n",
        "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
        "        packed_output, _ = self.lstm(packed_inp)\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
        "        combined = self.dropout(combined)\n",
        "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
        "\n",
        "        emission_scores = self.emission(combined)\n",
        "        # emission_scores => [batch_size, seq_len, tag_size]\n",
        "\n",
        "        # to store the tags predicted at each time step\n",
        "        # since at the begining every tag is start tag create the list with start tags\n",
        "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
        "        # tags => [batch_size, tag_size, 1]\n",
        "\n",
        "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
        "        # scores_upto_t => [batch_size, 1, tag_size]\n",
        "\n",
        "        for i in range(1, max(lengths)):\n",
        "            # get the current batch_size\n",
        "            batch_t = mask[:, i].sum()\n",
        "\n",
        "            # get the accumulated scores till now (only the current batch size)\n",
        "            scores_unpad = scores_upto_t[:batch_t]\n",
        "            # scores_unpad => [batch_t, 1, tag_size]\n",
        "\n",
        "            # add the transition scores for this time step\n",
        "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
        "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            # add to the accumulation\n",
        "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
        "            # sum_scores => [batch_t, tag_size, tag_size]\n",
        "\n",
        "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
        "            max_ids_t = max_ids_t.tolist()\n",
        "            # max_scores_t => [batch_t, tag_size]\n",
        "            # max_ids_t => [batch_t, tag_size]\n",
        "\n",
        "            # add the current time step predicted tags \n",
        "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
        "            \n",
        "            # update the accumulation scores\n",
        "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
        "            # scores_upto_t => [batch_size, tag_size]\n",
        "\n",
        "        scores = scores_upto_t.squeeze(1)\n",
        "        # scores => [batch_size, tag_size]\n",
        "\n",
        "        _, max_ids = torch.max(scores, dim=1)\n",
        "        max_ids = max_ids.tolist()\n",
        "        # max_ids => [batch_size]\n",
        "\n",
        "        # tags => [batch_size, tag_size, seq_len]\n",
        "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
        "        # tags => [batch_size, seq_len]\n",
        "\n",
        "        return tags\n",
        "\n"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEY0Z8WMVmZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "b2aa5d57-9b7c-4161-e86c-af6d51549a2a"
      },
      "source": [
        "vocab_size = len(words_vocab)\n",
        "sent_pad_token = words_vocab[words_vocab.PAD]\n",
        "tag_start_token = tags_vocab[tags_vocab.START]\n",
        "emb_dim = 50\n",
        "hid_dim = 200\n",
        "char_emb_dim = 20\n",
        "char_hid_dim = 50\n",
        "char_vocab_size = len(chars_vocab)\n",
        "tag_vocab_size = len(tags_vocab)\n",
        "model = CharBiLSTMCRF(\n",
        "    vocab_size,\n",
        "    emb_dim,\n",
        "    hid_dim,\n",
        "    char_emb_dim,\n",
        "    char_hid_dim,\n",
        "    char_vocab_size,\n",
        "    tag_vocab_size,\n",
        "    sent_pad_token,\n",
        "    tag_start_token\n",
        ")\n",
        "model.to(device)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CharBiLSTMCRF(\n",
              "  (char_embedding): Embedding(34, 20, padding_idx=0)\n",
              "  (char_lstm): LSTM(20, 50, batch_first=True, bidirectional=True)\n",
              "  (embedding): Embedding(9620, 50, padding_idx=0)\n",
              "  (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
              "  (emission): Linear(in_features=400, out_features=20, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuu7YjwQt3-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15a0b3fa-7bac-40fc-812b-44f47a2190df"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,002,100 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fpc9vWq3EY3",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKhNhP5_uFsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv1kwAoG3IzE",
        "colab_type": "text"
      },
      "source": [
        "### Training Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJQZHAmGuP-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        sentences = batch[0].to(device)\n",
        "        words = batch[1].to(device)\n",
        "        tags = batch[2].to(device)\n",
        "        seq_lengths = batch[3]\n",
        "        # sentences => [batch_size, seq_len]\n",
        "        # words => [batch_size, seq_len, word_len]\n",
        "        # tags => [batch_size, seq_len]\n",
        "        # seq_lengths => [batch_size]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_loss = model(sentences, seq_lengths, words, tags)\n",
        "        # batch_loss => [batch_size]\n",
        "\n",
        "        loss = batch_loss.mean()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += batch_loss.sum().item()\n",
        "        total_sentences += len(sentences)\n",
        "\n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeoX6uxx3MVe",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-UR_62uS0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    total_sentences = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            sentences = batch[0].to(device)\n",
        "            words = batch[1].to(device)\n",
        "            tags = batch[2].to(device)\n",
        "            seq_lengths = batch[3]\n",
        "            # sentences => [batch_size, seq_len]\n",
        "            # words => [batch_size, seq_len, word_len]\n",
        "            # tags => [batch_size, seq_len]\n",
        "            # seq_lengths => [batch_size]\n",
        "\n",
        "            batch_loss = model(sentences, seq_lengths, words, tags)\n",
        "            # batch_loss => [batch_size]\n",
        "\n",
        "            loss = batch_loss.mean()\n",
        "\n",
        "            epoch_loss += batch_loss.sum().item()\n",
        "            total_sentences += len(sentences)\n",
        "        \n",
        "    return epoch_loss / total_sentences\n"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urAtI4W3OUf",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8_N8-U6uUtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL5kQHBluWkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "4b891202-39f6-48fd-d198-2f13b3743996"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 2\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
        "    valid_loss = evaluate(model, valid_data_loader)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 9.061 | Val. Loss: 1.719\n",
            "Epoch: 02 | Epoch Time: 2m 8s\n",
            "\tTrain Loss: 1.742 | Val. Loss: 1.550\n",
            "Epoch: 03 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 1.577 | Val. Loss: 1.486\n",
            "Epoch: 04 | Epoch Time: 2m 7s\n",
            "\tTrain Loss: 1.491 | Val. Loss: 1.468\n",
            "Epoch: 05 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 1.439 | Val. Loss: 1.454\n",
            "Epoch: 06 | Epoch Time: 2m 9s\n",
            "\tTrain Loss: 1.403 | Val. Loss: 1.472\n",
            "Epoch: 07 | Epoch Time: 2m 4s\n",
            "\tTrain Loss: 1.375 | Val. Loss: 1.443\n",
            "Epoch: 08 | Epoch Time: 2m 2s\n",
            "\tTrain Loss: 1.343 | Val. Loss: 1.465\n",
            "Epoch: 09 | Epoch Time: 2m 2s\n",
            "\tTrain Loss: 1.329 | Val. Loss: 1.448\n",
            "Epoch: 10 | Epoch Time: 2m 3s\n",
            "\tTrain Loss: 1.314 | Val. Loss: 1.477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIXBCe7S3c3y",
        "colab_type": "text"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqDAWdc8vVAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2572b252-a16b-436a-d319-9e3917abd7c8"
      },
      "source": [
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKC73CrN3Ycb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bd44137-b80f-4642-baa5-5bea196ccda1"
      },
      "source": [
        "test_loss = evaluate(model, test_data_loader)\n",
        "print(f'Test Loss: {test_loss:.3f}')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 1.436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEH5FeEBt4BY",
        "colab_type": "text"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWQOhx3g3lmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inference(sentence):\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [words_vocab[words_vocab.START]] + sentence.split() + [words_vocab[words_vocab.END]]\n",
        "    else:\n",
        "        tokens = sentence\n",
        "    \n",
        "    chars = [['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in tokens[1:-1]] + [['<END>']]\n",
        "\n",
        "    char_seq = []\n",
        "    for word in chars:\n",
        "        word_len = len(word)\n",
        "        # truncate the word if it is greater than max_word_len\n",
        "        if word_len > MAX_WORD_LEN:\n",
        "            word = word[:MAX_WORD_LEN]\n",
        "        # pad the word if it less\n",
        "        else:\n",
        "            pad_length = MAX_WORD_LEN - word_len\n",
        "            word = word + [chars_vocab.PAD] * pad_length\n",
        "        \n",
        "        # convert the chars into numerical format\n",
        "        char_ids = []\n",
        "        for each_char in word: \n",
        "            char_ids.append(chars_vocab[each_char])\n",
        "        char_seq.append(char_ids)\n",
        "\n",
        "    # numericalize\n",
        "    token_ids = [words_vocab[tok] for tok in tokens]\n",
        "    \n",
        "    # seq length\n",
        "    sent_length = [len(token_ids)]\n",
        "\n",
        "    # create tensors\n",
        "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
        "    sent_tensor = sent_tensor.unsqueeze(0)\n",
        "    # sent_tensor => [1, seq_len]\n",
        "\n",
        "    char_tensor = torch.LongTensor(char_seq).to(device)\n",
        "    char_tensor = char_tensor.unsqueeze(0)\n",
        "    # char_tensor => [1, seq_len, word_len]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predictions = model.predict(sent_tensor, sent_length, char_tensor)\n",
        "    \n",
        "    predictions = predictions[0]\n",
        "    predicted_tags = []\n",
        "    for i in predictions:\n",
        "        predicted_tags.append(tags_vocab.id2word(i))\n",
        "    \n",
        "    return tokens, predicted_tags\n"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrgvPn1vj0W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "82f12031-5f34-4575-826b-a8d67a863c0d"
      },
      "source": [
        "sentence = test_sentences[0]\n",
        "actual_tags = test_tags[0]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<START>\t\t<START>\t\t✔\t\t<START>\n",
            "O\t\tO\t\t✔\t\tThe\n",
            "O\t\tO\t\t✔\t\toffice\n",
            "O\t\tO\t\t✔\t\tof\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "B-gpe\t\tB-gpe\t\t✔\t\tIsraeli\n",
            "O\t\tO\t\t✔\t\tprime\n",
            "O\t\tO\t\t✔\t\tminister\n",
            "O\t\tO\t\t✔\t\tsays\n",
            "O\t\tO\t\t✔\t\ta\n",
            "O\t\tO\t\t✔\t\tvisit\n",
            "O\t\tO\t\t✔\t\tto\n",
            "B-geo\t\tB-geo\t\t✔\t\tIsrael\n",
            "O\t\tO\t\t✔\t\tby\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "O\t\tO\t\t✔\t\tforeign\n",
            "O\t\tO\t\t✔\t\tministers\n",
            "O\t\tO\t\t✔\t\tof\n",
            "B-geo\t\tB-gpe\t\t✘\t\tEgypt\n",
            "O\t\tO\t\t✔\t\tand\n",
            "B-gpe\t\tB-gpe\t\t✔\t\tJordan\n",
            "O\t\tO\t\t✔\t\twill\n",
            "O\t\tO\t\t✔\t\ttake\n",
            "O\t\tO\t\t✔\t\tplace\n",
            "B-tim\t\tB-tim\t\t✔\t\tJuly\n",
            "I-tim\t\tI-tim\t\t✔\t\t25\n",
            "O\t\tO\t\t✔\t\t,\n",
            "O\t\tO\t\t✔\t\tnot\n",
            "O\t\tO\t\t✔\t\tthis\n",
            "O\t\tO\t\t✔\t\tweek\n",
            "O\t\tO\t\t✔\t\tas\n",
            "O\t\tO\t\t✔\t\tpreviously\n",
            "O\t\tO\t\t✔\t\tplanned\n",
            "O\t\tO\t\t✔\t\t.\n",
            "<END>\t\t<END>\t\t✔\t\t<END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UDJLIFLzlsN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "461f1d46-5c27-4b88-8c0d-b049e4f96a70"
      },
      "source": [
        "sentence = test_sentences[10]\n",
        "actual_tags = test_tags[10]\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "<START>\t\t<START>\t\t✔\t\t<START>\n",
            "O\t\tO\t\t✔\t\tAn\n",
            "B-gpe\t\tB-gpe\t\t✔\t\tIraqi\n",
            "O\t\tO\t\t✔\t\tmilitant\n",
            "O\t\tO\t\t✔\t\tgroup\n",
            "O\t\tO\t\t✔\t\t(\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "B-org\t\tB-org\t\t✔\t\tIslamic\n",
            "I-org\t\tI-org\t\t✔\t\tArmy\n",
            "O\t\tO\t\t✔\t\tof\n",
            "B-geo\t\tB-geo\t\t✔\t\tIraq\n",
            "O\t\tO\t\t✔\t\t)\n",
            "O\t\tO\t\t✔\t\tposted\n",
            "O\t\tO\t\t✔\t\ta\n",
            "O\t\tO\t\t✔\t\tvideo\n",
            "O\t\tO\t\t✔\t\ton\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "O\t\tO\t\t✔\t\tInternet\n",
            "B-tim\t\tB-tim\t\t✔\t\ttoday\n",
            "O\t\tO\t\t✔\t\tthat\n",
            "O\t\tO\t\t✔\t\tshowed\n",
            "O\t\tO\t\t✔\t\ta\n",
            "O\t\tO\t\t✔\t\tblindfolded\n",
            "O\t\tO\t\t✔\t\tman\n",
            "O\t\tO\t\t✔\t\tbeing\n",
            "O\t\tO\t\t✔\t\tshot\n",
            "O\t\tO\t\t✔\t\tin\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "O\t\tO\t\t✔\t\tback\n",
            "O\t\tO\t\t✔\t\tof\n",
            "O\t\tO\t\t✔\t\tthe\n",
            "O\t\tO\t\t✔\t\thead\n",
            "O\t\tO\t\t✔\t\t.\n",
            "<END>\t\t<END>\t\t✔\t\t<END>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jyhMAl63I7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2d62a71b-d44b-4dde-b021-ac5b841e2838"
      },
      "source": [
        "sentence = \"I like to live in New York\"\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
        "    print(f\"{pred_tag}\\t\\t{token}\")"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "O\t\tI\n",
            "O\t\tlike\n",
            "O\t\tto\n",
            "O\t\tlive\n",
            "O\t\tin\n",
            "B-geo\t\tNew\n",
            "I-geo\t\tYork\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srjLeOA53aRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2bd04f47-5c08-4291-e517-6605b04332e4"
      },
      "source": [
        "sentence = \"My dream is to work at Google\"\n",
        "tokens, predicted_tag_ids = inference(sentence)\n",
        "\n",
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
        "    print(f\"{pred_tag}\\t\\t{token}\")"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred. Tag\tToken\n",
            "\n",
            "O\t\tMy\n",
            "O\t\tdream\n",
            "O\t\tis\n",
            "O\t\tto\n",
            "O\t\twork\n",
            "O\t\tat\n",
            "B-org\t\tGoogle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFkVZrIf38D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
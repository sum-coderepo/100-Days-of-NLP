{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Augmentation in NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNS4RptmAHuhjqf5bTHOSNV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graviraja/100-Days-of-NLP/blob/architectures/Data%20Augmentation%20in%20NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVGHbOWK-4WL",
        "colab_type": "text"
      },
      "source": [
        "### Drive mounting\n",
        "\n",
        "Using drive mounting to use the glove file which is there in my drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh8ie7Je-lyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bf547e62-60bb-429b-eeae-c719cfc2a65c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xZBt9sq1Gb9",
        "colab_type": "text"
      },
      "source": [
        "### Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw574lNzueNZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "ad23115d-3264-4d41-924b-444dd00b1857"
      },
      "source": [
        "!pip install nlpaug python-dotenv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 2.2MB/s \n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/16/28d434b28c5be29a6af8fd0e3a2bda3bd30500ef0cd17bc79f7a6793a8d4/python_dotenv-0.14.0-py2.py3-none-any.whl\n",
            "Installing collected packages: nlpaug, python-dotenv\n",
            "Successfully installed nlpaug-0.0.14 python-dotenv-0.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SObV9jeQysZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install googletrans -q"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2I_vJyK20XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c5ddd4fa-c180-4f29-d2e1-e95a1bae259b"
      },
      "source": [
        "!pip install contractions -q"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 317kB 3.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 19.6MB/s \n",
            "\u001b[?25h  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ylxPCXAkI6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "2e37ef98-2622-4980-eb1d-f5b8f35481e5"
      },
      "source": [
        "!pip install transformers -q"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 778kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 17.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 23.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 29.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6t89LAsvNLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "51d97435-1290-450f-8168-e2f473d4ad47"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UT_5urRtdt1",
        "colab_type": "text"
      },
      "source": [
        "### Synonym-based substitution\n",
        "\n",
        "In this technique, a word is picked randomly from the sentence and then it is replaced by its synonym using a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ6Sl0-irTQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlpaug.augmenter.word as naw"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC-mz8X8u-cc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aug = naw.SynonymAug(aug_src='wordnet')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se96ucObvx7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C18VeuQqvV1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "808a60f3-634f-4626-9c81-755031c2ebf6"
      },
      "source": [
        "# word is picked randomly. run multiple time to get multiple augmentations\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(5):\n",
        "        augmented_text = aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick brown dodger jump over the work shy dog .\n",
            "Augmented: The immediate robert brown charles james fox jumps over the lazy dog .\n",
            "Augmented: The flying brown fox jumps all over the faineant dog .\n",
            "Augmented: The nimble brown fox alternate over the lazy hound .\n",
            "Augmented: The agile brown charles james fox jumps over the lazy wienerwurst .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not that awing\n",
            "Augmented: The product was non that awesome\n",
            "Augmented: The product embody not that awesome\n",
            "Augmented: The product was non that awesome\n",
            "Augmented: The product was not that awing\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBT5sBuj46Cm",
        "colab_type": "text"
      },
      "source": [
        "### Antonym-based substitution\n",
        "\n",
        "Same as above. Instead of synonym word is replace by antonym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLtBMT-5FHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "265d7e4b-edea-4aca-83ec-95b91973e8c6"
      },
      "source": [
        "aug = naw.AntonymAug()\n",
        "texts = [\"He is a good boy.\", \"I like the movie\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(5):\n",
        "        augmented_text = aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: He is a good boy.\n",
            "\n",
            "Augmented: He is a good female child .\n",
            "Augmented: He differ a good boy .\n",
            "Augmented: He differ a good boy .\n",
            "Augmented: He is a good boy .\n",
            "Augmented: He is a evil boy .\n",
            "--------------------------------------------------\n",
            "Original: I like the movie\n",
            "\n",
            "Augmented: I dislike the movie\n",
            "Augmented: I dislike the movie\n",
            "Augmented: I like the movie\n",
            "Augmented: I dislike the movie\n",
            "Augmented: I dislike the movie\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1nNSahmtEwn",
        "colab_type": "text"
      },
      "source": [
        "### Back Translation\n",
        "\n",
        "In this method, the sentence will be translated into a different language and then back-translated to source language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjQqoGbstGHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from googletrans import Translator"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0ylhZnFx0mo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "684dba1c-83b9-4f3a-ab1d-8840b88c3be7"
      },
      "source": [
        "translator = Translator()\n",
        "langs = ['fr', 'de', 'ja', 'la', 'hi', 'ko', 'eo', 'es']\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for l in langs:\n",
        "        translated = translator.translate(text, dest=l)\n",
        "        back_translated = translator.translate(translated.text, dest='en')\n",
        "        print(f\"Augmented: {back_translated.text}\")\n",
        "    print(f\"-\"*50)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick brown fox jumps over the lazy dog.\n",
            "Augmented: The fast brown fox jumps over the lazy dog.\n",
            "Augmented: A quick brown fox jumps over a lazy dog.\n",
            "Augmented: The quick brown fox jumps over the lazy dog.\n",
            "Augmented: The quick brown fox jumps over the lazy dog.\n",
            "Augmented: The fast brown fox jumps over the lazy dog.\n",
            "Augmented: The fast brown fox jumps over the lazy dog.\n",
            "Augmented: The fast brown fox jumps on the lazy dog.\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not that great\n",
            "Augmented: The product was not that great\n",
            "Augmented: The product was so great\n",
            "Augmented: This product is not terrible\n",
            "Augmented: Product was not so terrible\n",
            "Augmented: The product wasn't awesome\n",
            "Augmented: The product was not so awesome\n",
            "Augmented: The product was not that great\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUAaBjpJ2H-K",
        "colab_type": "text"
      },
      "source": [
        "Advanced Machine translation repos also can be used and translate the sentence into other language using beam search and then back-translate the beam generated translations. (This would require more compute power)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwx7rP8atGrs",
        "colab_type": "text"
      },
      "source": [
        "### Text Surface Transformation\n",
        "\n",
        "This is a simple pattern matching transformation using regex. An example would be to expand/contract the verbal forms. Can also be extended to custom cases using regex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNKYmSys3khS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import contractions"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzYv8JfQtKoK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "f4029bd4-76f5-4cfd-fb0e-ebcdb98cfe72"
      },
      "source": [
        "text = \"you're amazing\"\n",
        "print(contractions.fix(text))\n",
        "\n",
        "text = \"yall're happy now?\"\n",
        "print(contractions.fix(text))\n",
        "\n",
        "text = \"I'm going to office\"\n",
        "print(contractions.fix(text))\n",
        "\n",
        "text = \"I gotta go to gym\"\n",
        "print(contractions.fix(text))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "you are amazing\n",
            "you all are happy now?\n",
            "I am going to office\n",
            "I got to go to gym\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0agtbz654Crw",
        "colab_type": "text"
      },
      "source": [
        "### Random Noise Injection\n",
        "\n",
        "The idea of this method is to inject noise in the text so that the model trained is robust to perturbations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNJmTB4H5kpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlpaug.augmenter.char as nac"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poHSVIZF3mYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "cdc771fc-7f54-47cd-cc4b-541c7be60384"
      },
      "source": [
        "# This method tries to simulate common errors that happen \n",
        "# when typing on a QWERTY layout keyboard due to keys that \n",
        "# are very near to each other. The errors are injected based on keyboard distance.\n",
        "keyboard_aug = nac.KeyboardAug()\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(5):\n",
        "        augmented_text = keyboard_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick vrown fox jumps over the Oazy dog .\n",
            "Augmented: The wuick brown fox jumps ov#r the lWzy dog .\n",
            "Augmented: The quock brown fox jumps ovFr the lazy dog .\n",
            "Augmented: The quifk brown fox jumps over the lazy dog .\n",
            "Augmented: The quick bfown fox jumps over the lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The peKduct was not that awesome\n",
            "Augmented: The product was not that swssome\n",
            "Augmented: The (rpduct was not that awesome\n",
            "Augmented: The product was not that awDso,e\n",
            "Augmented: The p4odjct was not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB_03zg-6Jcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "cacc3ca2-f867-4553-f3d5-66c8796aa83e"
      },
      "source": [
        "# inserting a random character\n",
        "\n",
        "randchar_aug = nac.RandomCharAug(action='insert')\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randchar_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick brown fox jumps gover the lazy dog .\n",
            "Augmented: The quick browpn fox jumps over the lazy dog .\n",
            "Augmented: The quick ibrown fox jumps over the laDzy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The Cpr!oduct was not that awesome\n",
            "Augmented: The produvc$t was not that awesome\n",
            "Augmented: The product was not thaot awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mApDis0o6ebq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f7fb446b-d9cc-4055-88d5-7ef7ced23050"
      },
      "source": [
        "# substituting a random character\n",
        "randchar_aug = nac.RandomCharAug(action='substitute')\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randchar_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick brown fox jumps over the la@y dog .\n",
            "Augmented: The quick brown fox jumps ove% the laDy dog .\n",
            "Augmented: The quicQ brown fox jumps ovTr the lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not tEat awesome\n",
            "Augmented: The p+oduc2 was not that awesome\n",
            "Augmented: The product was not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpI-pAK6ikU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "e4fdc37a-85f5-490c-d514-5cdb4ca81fdf"
      },
      "source": [
        "# deleting a random character\n",
        "randchar_aug = nac.RandomCharAug(action='delete')\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randchar_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quck bown fox jumps over the lzy dog .\n",
            "Augmented: The quick brow fox jumps over the laz dog .\n",
            "Augmented: The quick brown fox jumps over the lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not tat awesome\n",
            "Augmented: The rduct was not that awesome\n",
            "Augmented: The prdct was not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doc1VG5f7CIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "bee18709-f62c-44f3-f4e9-1aca1783fc27"
      },
      "source": [
        "# swapping characters\n",
        "randchar_aug = nac.RandomCharAug(action='swap')\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randchar_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quikc brown fox jumps over the alzy dog .\n",
            "Augmented: The quick bronw fox jumps over the layz dog .\n",
            "Augmented: The qucik brown fox jumps over the alzy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not htat awesome\n",
            "Augmented: The product was not that waesoem\n",
            "Augmented: The product was not taht awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7fXJ2SU7DM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9b2476e0-c162-45fc-c429-7fca7d220515"
      },
      "source": [
        "# random WORD swapping\n",
        "randword_aug = naw.RandomWordAug(action=\"swap\")\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randword_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick jumps brown fox over the dog lazy .\n",
            "Augmented: The quick brown fox jumps over lazy the dog .\n",
            "Augmented: Quick the fox brown jumps the over lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not awesome that\n",
            "Augmented: The product was that not awesome\n",
            "Augmented: The was product not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AKCiJuM7ec7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "904c5d9d-0d6d-48c8-b007-4b4258d76d08"
      },
      "source": [
        "# random WORD deleting\n",
        "randword_aug = naw.RandomWordAug(action=\"delete\")\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randword_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick brown jumps over lazy .\n",
            "Augmented: The fox jumps over the lazy .\n",
            "Augmented: Quick brown fox over the dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product not that awesome\n",
            "Augmented: Product was not that awesome\n",
            "Augmented: The was not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pewk90Iz7pFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b4a1d3fd-687f-417e-c4a5-21c28b9b77f4"
      },
      "source": [
        "# randomly SPLIT the WORD into two \n",
        "\n",
        "randword_aug = naw.SplitAug()\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = randword_aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The quick br own fox jumps ov er the la zy dog .\n",
            "Augmented: The qui ck brown fox jum ps o ver the lazy dog .\n",
            "Augmented: The qu ick b rown fox jumps o ver the lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was not t hat awesome\n",
            "Augmented: The product was not that awes ome\n",
            "Augmented: The p roduct was not that awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY2eRa418gBc",
        "colab_type": "text"
      },
      "source": [
        "### Using Pre-trained Word Embeddings\n",
        "\n",
        "In this method, pre-trained word-embeddings like word2vec / glove / fasttext will be used to insert/substitute the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5v6uUDF_E9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlpaug.util.file.download import DownloadUtil\n",
        "# DownloadUtil.download_word2vec(dest_dir='.') # Download word2vec model\n",
        "# DownloadUtil.download_glove(model_name='glove.6B', dest_dir='.') # Download GloVe model\n",
        "# DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0fhYc95_GXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "13795269-5ed8-4132-8d65-d298160e6df4"
      },
      "source": [
        "!unzip \"./drive/My Drive/glove.6B.zip\""
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./drive/My Drive/glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZuYXuX27yWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "6e86f7c9-26c9-45c5-eb43-a5e9c5008737"
      },
      "source": [
        "# model_type could be word2vec, glove, fasttext\n",
        "\n",
        "aug = naw.WordEmbsAug(model_type='glove', model_path='glove.6B.200d.txt', action=\"insert\")\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: vitaris The quick brown fox jumps milsons over the sephirot lazy dog .\n",
            "Augmented: abundance The quick brown 9-hole fox jumps over the lazy dunc dog .\n",
            "Augmented: 1,748 The quick gubaidulina brown fox jumps over the denso lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product miglio was not that awesome\n",
            "Augmented: The product was not that champi awesome\n",
            "Augmented: The product was not that stewed awesome\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKrWQ_7s9aQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "891c7dea-2934-473f-ff95-93e15b4b5739"
      },
      "source": [
        "aug = naw.WordEmbsAug(model_type='glove', model_path='glove.6B.200d.txt', action=\"substitute\")\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: The quick brown fox jumps over the lazy dog.\n",
            "\n",
            "Augmented: The go brown fox slower ago the lazy dog .\n",
            "Augmented: The quick brown upn jumps over the cat stray .\n",
            "Augmented: The needed wright film jumps over the lazy dog .\n",
            "--------------------------------------------------\n",
            "Original: The product was not that awesome\n",
            "\n",
            "Augmented: The product was instead that awesome\n",
            "Augmented: The product was not there awesome\n",
            "Augmented: The product was not that greatness\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAx69lJg_u9Q",
        "colab_type": "text"
      },
      "source": [
        "### Using Contextual Word Embeddings\n",
        "\n",
        "In this method, contextual word embeddings like BERT / DistilBERT / RoBERTA will be used to insert/substitute the word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJjeSb8AXzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "from transformers import DistilBertTokenizer, DistilBertForMaskedLM"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy2hbZFAF9Wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nlpaug.augmenter.word import ContextualWordEmbsAug"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-6wqqeb_cqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "1df3b770-c905-4eb8-8166-42b5421cee3f"
      },
      "source": [
        "aug = ContextualWordEmbsAug(model_path='distilbert-base-uncased', action='substitute')\n",
        "\n",
        "texts = [\"The quick brown fox jumps over the lazy dog.\", \"The product was not that awesome\"]\n",
        "\n",
        "for text in texts:\n",
        "    print(f\"Original: {text}\\n\")\n",
        "\n",
        "    for _ in range(3):\n",
        "        augmented_text = aug.augment(text)\n",
        "        print(f\"Augmented: {augmented_text}\")\n",
        "    print(\"-\"*50)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-82f3cc4a6663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContextualWordEmbsAug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distilbert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'substitute'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"The quick brown fox jumps over the lazy dog.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The product was not that awesome\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpaug/augmenter/word/context_word_embs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, action, temperature, top_k, top_p, name, aug_min, aug_max, aug_p, stopwords, skip_unknown_word, device, force_reload, optimize, stopwords_regex, verbose, include_detail)\u001b[0m\n\u001b[1;32m     94\u001b[0m         self.model = self.get_model(\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             top_p=top_p, optimize=optimize)\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Override stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'xlnet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'roberta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpaug/augmenter/word/context_word_embs.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(cls, model_path, device, force_reload, temperature, top_k, top_p, optimize)\u001b[0m\n\u001b[1;32m    324\u001b[0m     def get_model(cls, model_path, device='cuda', force_reload=False, temperature=1.0, top_k=None, top_p=0.0,\n\u001b[1;32m    325\u001b[0m                   optimize=None):\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minit_context_word_embs_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpaug/augmenter/word/context_word_embs.py\u001b[0m in \u001b[0;36minit_context_word_embs_model\u001b[0;34m(model_path, device, force_reload, temperature, top_k, top_p, optimize)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'distilbert'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistilBert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'roberta'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRoberta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nlpaug/model/lang_models/distilbert.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, temperature, top_k, top_p, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# self.tokenizer = AutoTokenizer.from_pretrained(model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# self.model = AutoModel.from_pretrained(model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistilBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DistilBertTokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf85w6DfHZlT",
        "colab_type": "text"
      },
      "source": [
        "Some issue in the code. An issue has been raised [here](https://github.com/makcedward/nlpaug/issues/139) . Will update it as soon as the issue got resolved. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmPw-ldxANf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}